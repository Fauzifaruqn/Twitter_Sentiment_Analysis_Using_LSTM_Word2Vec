{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # provide sql-like data manipulation tools. very handy.\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np # high dimensional vector computing library.\n",
    "from string import punctuation\n",
    "from random import shuffle\n",
    "from builtins import str\n",
    "import string\n",
    "import random\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence # we'll talk about this down below\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim.models.keyedvectors as word2vec #need to use due to depreceated model\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import LSTM,BatchNormalization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve,  roc_auc_score, classification_report\n",
    "\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname) s : %(message)s', level=logging.INFO)\n",
    "#Set random seed\n",
    "np.random.seed(24)\n",
    "#read CSV file containing tweets and labels, using Pandas , to get a dataframe\n",
    "n=1000000\n",
    "n_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_pickle('./Processedtweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[o, how, dare, they, im, gonna, look, on, da, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[no, one, was, in, front, of, me, i, took, hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[ah, client's, poxy, vpn, failed, again]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[why, aren't, i, at, coachella, i'll, just, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[ta, very, much, just, updating, our, twitter,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                             tokens\n",
       "0          1  [o, how, dare, they, im, gonna, look, on, da, ...\n",
       "1          1  [no, one, was, in, front, of, me, i, took, hun...\n",
       "2          0           [ah, client's, poxy, vpn, failed, again]\n",
       "3          0  [why, aren't, i, at, coachella, i'll, just, wa...\n",
       "4          1  [ta, very, much, just, updating, our, twitter,..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(data.head(n).tokens),\n",
    "                                                    np.array(data.head(n).Sentiment), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['whooo',\n",
       "  'i',\n",
       "  'just',\n",
       "  'thought',\n",
       "  'it',\n",
       "  'was',\n",
       "  'an',\n",
       "  'interesting',\n",
       "  'topic',\n",
       "  'for',\n",
       "  'you'],\n",
       " ['it', 'was', 'ok', 'cute', 'times'],\n",
       " 1,\n",
       " 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[2],x_test[2],y_train[2],y_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-14 12:22:14,186 : INFO : collecting all words and their counts\n",
      "2019-05-14 12:22:14,195 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-14 12:22:14,329 : INFO : PROGRESS: at sentence #10000, processed 124843 words, keeping 15048 word types\n",
      "2019-05-14 12:22:14,441 : INFO : PROGRESS: at sentence #20000, processed 250015 words, keeping 23786 word types\n",
      "2019-05-14 12:22:14,527 : INFO : PROGRESS: at sentence #30000, processed 374761 words, keeping 30853 word types\n",
      "2019-05-14 12:22:14,640 : INFO : PROGRESS: at sentence #40000, processed 500135 words, keeping 37174 word types\n",
      "2019-05-14 12:22:14,742 : INFO : PROGRESS: at sentence #50000, processed 624689 words, keeping 42825 word types\n",
      "2019-05-14 12:22:14,841 : INFO : PROGRESS: at sentence #60000, processed 749282 words, keeping 48210 word types\n",
      "2019-05-14 12:22:14,925 : INFO : PROGRESS: at sentence #70000, processed 873376 words, keeping 53225 word types\n",
      "2019-05-14 12:22:15,026 : INFO : PROGRESS: at sentence #80000, processed 998065 words, keeping 57952 word types\n",
      "2019-05-14 12:22:15,123 : INFO : PROGRESS: at sentence #90000, processed 1121959 words, keeping 62722 word types\n",
      "2019-05-14 12:22:15,214 : INFO : PROGRESS: at sentence #100000, processed 1246598 words, keeping 67142 word types\n",
      "2019-05-14 12:22:15,299 : INFO : PROGRESS: at sentence #110000, processed 1371151 words, keeping 71566 word types\n",
      "2019-05-14 12:22:15,386 : INFO : PROGRESS: at sentence #120000, processed 1495178 words, keeping 75829 word types\n",
      "2019-05-14 12:22:15,485 : INFO : PROGRESS: at sentence #130000, processed 1619297 words, keeping 79979 word types\n",
      "2019-05-14 12:22:15,560 : INFO : PROGRESS: at sentence #140000, processed 1744637 words, keeping 84172 word types\n",
      "2019-05-14 12:22:15,659 : INFO : PROGRESS: at sentence #150000, processed 1868136 words, keeping 88085 word types\n",
      "2019-05-14 12:22:15,746 : INFO : PROGRESS: at sentence #160000, processed 1991825 words, keeping 92063 word types\n",
      "2019-05-14 12:22:15,842 : INFO : PROGRESS: at sentence #170000, processed 2115972 words, keeping 95985 word types\n",
      "2019-05-14 12:22:15,929 : INFO : PROGRESS: at sentence #180000, processed 2240412 words, keeping 99794 word types\n",
      "2019-05-14 12:22:16,017 : INFO : PROGRESS: at sentence #190000, processed 2364193 words, keeping 103439 word types\n",
      "2019-05-14 12:22:16,104 : INFO : PROGRESS: at sentence #200000, processed 2488531 words, keeping 107085 word types\n",
      "2019-05-14 12:22:16,181 : INFO : PROGRESS: at sentence #210000, processed 2613206 words, keeping 110700 word types\n",
      "2019-05-14 12:22:16,278 : INFO : PROGRESS: at sentence #220000, processed 2738980 words, keeping 114264 word types\n",
      "2019-05-14 12:22:16,377 : INFO : PROGRESS: at sentence #230000, processed 2862917 words, keeping 117663 word types\n",
      "2019-05-14 12:22:16,468 : INFO : PROGRESS: at sentence #240000, processed 2986713 words, keeping 120939 word types\n",
      "2019-05-14 12:22:16,554 : INFO : PROGRESS: at sentence #250000, processed 3111453 words, keeping 124328 word types\n",
      "2019-05-14 12:22:16,652 : INFO : PROGRESS: at sentence #260000, processed 3235788 words, keeping 127634 word types\n",
      "2019-05-14 12:22:16,738 : INFO : PROGRESS: at sentence #270000, processed 3359837 words, keeping 130904 word types\n",
      "2019-05-14 12:22:16,828 : INFO : PROGRESS: at sentence #280000, processed 3484046 words, keeping 134384 word types\n",
      "2019-05-14 12:22:16,913 : INFO : PROGRESS: at sentence #290000, processed 3609537 words, keeping 137706 word types\n",
      "2019-05-14 12:22:17,012 : INFO : PROGRESS: at sentence #300000, processed 3734198 words, keeping 140874 word types\n",
      "2019-05-14 12:22:17,104 : INFO : PROGRESS: at sentence #310000, processed 3858523 words, keeping 144126 word types\n",
      "2019-05-14 12:22:17,183 : INFO : PROGRESS: at sentence #320000, processed 3983478 words, keeping 147307 word types\n",
      "2019-05-14 12:22:17,289 : INFO : PROGRESS: at sentence #330000, processed 4108215 words, keeping 150340 word types\n",
      "2019-05-14 12:22:17,377 : INFO : PROGRESS: at sentence #340000, processed 4233910 words, keeping 153571 word types\n",
      "2019-05-14 12:22:17,469 : INFO : PROGRESS: at sentence #350000, processed 4358385 words, keeping 156588 word types\n",
      "2019-05-14 12:22:17,557 : INFO : PROGRESS: at sentence #360000, processed 4482808 words, keeping 159622 word types\n",
      "2019-05-14 12:22:17,656 : INFO : PROGRESS: at sentence #370000, processed 4607594 words, keeping 162636 word types\n",
      "2019-05-14 12:22:17,731 : INFO : PROGRESS: at sentence #380000, processed 4733489 words, keeping 165645 word types\n",
      "2019-05-14 12:22:17,822 : INFO : PROGRESS: at sentence #390000, processed 4857391 words, keeping 168704 word types\n",
      "2019-05-14 12:22:17,919 : INFO : PROGRESS: at sentence #400000, processed 4982819 words, keeping 171710 word types\n",
      "2019-05-14 12:22:18,004 : INFO : PROGRESS: at sentence #410000, processed 5107955 words, keeping 174593 word types\n",
      "2019-05-14 12:22:18,128 : INFO : PROGRESS: at sentence #420000, processed 5232331 words, keeping 177443 word types\n",
      "2019-05-14 12:22:18,215 : INFO : PROGRESS: at sentence #430000, processed 5356412 words, keeping 180369 word types\n",
      "2019-05-14 12:22:18,303 : INFO : PROGRESS: at sentence #440000, processed 5481136 words, keeping 183218 word types\n",
      "2019-05-14 12:22:18,402 : INFO : PROGRESS: at sentence #450000, processed 5604901 words, keeping 186011 word types\n",
      "2019-05-14 12:22:18,512 : INFO : PROGRESS: at sentence #460000, processed 5730086 words, keeping 188853 word types\n",
      "2019-05-14 12:22:18,593 : INFO : PROGRESS: at sentence #470000, processed 5855209 words, keeping 191661 word types\n",
      "2019-05-14 12:22:18,683 : INFO : PROGRESS: at sentence #480000, processed 5979085 words, keeping 194456 word types\n",
      "2019-05-14 12:22:18,790 : INFO : PROGRESS: at sentence #490000, processed 6103649 words, keeping 197132 word types\n",
      "2019-05-14 12:22:18,891 : INFO : PROGRESS: at sentence #500000, processed 6229043 words, keeping 199897 word types\n",
      "2019-05-14 12:22:18,979 : INFO : PROGRESS: at sentence #510000, processed 6353928 words, keeping 202701 word types\n",
      "2019-05-14 12:22:19,071 : INFO : PROGRESS: at sentence #520000, processed 6477933 words, keeping 205383 word types\n",
      "2019-05-14 12:22:19,174 : INFO : PROGRESS: at sentence #530000, processed 6602981 words, keeping 208009 word types\n",
      "2019-05-14 12:22:19,263 : INFO : PROGRESS: at sentence #540000, processed 6727617 words, keeping 210702 word types\n",
      "2019-05-14 12:22:19,350 : INFO : PROGRESS: at sentence #550000, processed 6850647 words, keeping 213433 word types\n",
      "2019-05-14 12:22:19,450 : INFO : PROGRESS: at sentence #560000, processed 6975006 words, keeping 216014 word types\n",
      "2019-05-14 12:22:19,548 : INFO : PROGRESS: at sentence #570000, processed 7099473 words, keeping 218707 word types\n",
      "2019-05-14 12:22:19,632 : INFO : PROGRESS: at sentence #580000, processed 7223796 words, keeping 221361 word types\n",
      "2019-05-14 12:22:19,731 : INFO : PROGRESS: at sentence #590000, processed 7348893 words, keeping 223940 word types\n",
      "2019-05-14 12:22:19,823 : INFO : PROGRESS: at sentence #600000, processed 7473130 words, keeping 226569 word types\n",
      "2019-05-14 12:22:19,906 : INFO : PROGRESS: at sentence #610000, processed 7597377 words, keeping 229190 word types\n",
      "2019-05-14 12:22:20,024 : INFO : PROGRESS: at sentence #620000, processed 7721119 words, keeping 231783 word types\n",
      "2019-05-14 12:22:20,118 : INFO : PROGRESS: at sentence #630000, processed 7846894 words, keeping 234448 word types\n",
      "2019-05-14 12:22:20,216 : INFO : PROGRESS: at sentence #640000, processed 7971601 words, keeping 237060 word types\n",
      "2019-05-14 12:22:20,311 : INFO : PROGRESS: at sentence #650000, processed 8096637 words, keeping 239543 word types\n",
      "2019-05-14 12:22:20,395 : INFO : PROGRESS: at sentence #660000, processed 8220228 words, keeping 242180 word types\n",
      "2019-05-14 12:22:20,477 : INFO : PROGRESS: at sentence #670000, processed 8344846 words, keeping 244696 word types\n",
      "2019-05-14 12:22:20,566 : INFO : PROGRESS: at sentence #680000, processed 8469685 words, keeping 247214 word types\n",
      "2019-05-14 12:22:20,656 : INFO : PROGRESS: at sentence #690000, processed 8594251 words, keeping 249832 word types\n",
      "2019-05-14 12:22:20,738 : INFO : PROGRESS: at sentence #700000, processed 8717530 words, keeping 252363 word types\n",
      "2019-05-14 12:22:20,824 : INFO : PROGRESS: at sentence #710000, processed 8841997 words, keeping 254932 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-14 12:22:20,914 : INFO : PROGRESS: at sentence #720000, processed 8965858 words, keeping 257342 word types\n",
      "2019-05-14 12:22:20,998 : INFO : PROGRESS: at sentence #730000, processed 9089992 words, keeping 259709 word types\n",
      "2019-05-14 12:22:21,079 : INFO : PROGRESS: at sentence #740000, processed 9216033 words, keeping 262200 word types\n",
      "2019-05-14 12:22:21,185 : INFO : PROGRESS: at sentence #750000, processed 9340945 words, keeping 264666 word types\n",
      "2019-05-14 12:22:21,271 : INFO : PROGRESS: at sentence #760000, processed 9464972 words, keeping 267110 word types\n",
      "2019-05-14 12:22:21,350 : INFO : PROGRESS: at sentence #770000, processed 9590239 words, keeping 269582 word types\n",
      "2019-05-14 12:22:21,435 : INFO : PROGRESS: at sentence #780000, processed 9715095 words, keeping 272012 word types\n",
      "2019-05-14 12:22:21,526 : INFO : PROGRESS: at sentence #790000, processed 9839599 words, keeping 274517 word types\n",
      "2019-05-14 12:22:21,614 : INFO : collected 276959 word types from a corpus of 9963360 raw words and 800000 sentences\n",
      "2019-05-14 12:22:21,615 : INFO : Loading a fresh vocabulary\n",
      "2019-05-14 12:22:21,951 : INFO : min_count=15 retains 18054 unique words (6% of original 276959, drops 258905)\n",
      "2019-05-14 12:22:21,953 : INFO : min_count=15 leaves 9490509 word corpus (95% of original 9963360, drops 472851)\n",
      "2019-05-14 12:22:22,100 : INFO : deleting the raw counts dictionary of 276959 items\n",
      "2019-05-14 12:22:22,122 : INFO : sample=0.001 downsamples 58 most-common words\n",
      "2019-05-14 12:22:22,126 : INFO : downsampling leaves estimated 7394934 word corpus (77.9% of prior 9490509)\n",
      "2019-05-14 12:22:22,261 : INFO : estimated required memory for 18054 words and 200 dimensions: 37913400 bytes\n",
      "2019-05-14 12:22:22,262 : INFO : resetting layer weights\n",
      "2019-05-14 12:22:22,736 : INFO : training model with 3 workers on 18054 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-05-14 12:22:23,802 : INFO : EPOCH 1 - PROGRESS: at 3.50% examples, 245875 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:24,823 : INFO : EPOCH 1 - PROGRESS: at 7.20% examples, 257056 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:25,854 : INFO : EPOCH 1 - PROGRESS: at 10.11% examples, 240959 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:22:26,865 : INFO : EPOCH 1 - PROGRESS: at 13.63% examples, 244849 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:22:27,894 : INFO : EPOCH 1 - PROGRESS: at 16.74% examples, 240542 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:22:29,018 : INFO : EPOCH 1 - PROGRESS: at 19.05% examples, 224702 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:30,018 : INFO : EPOCH 1 - PROGRESS: at 21.88% examples, 222330 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:22:31,060 : INFO : EPOCH 1 - PROGRESS: at 24.90% examples, 221260 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:32,088 : INFO : EPOCH 1 - PROGRESS: at 28.49% examples, 225506 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:33,121 : INFO : EPOCH 1 - PROGRESS: at 32.11% examples, 228789 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:22:34,153 : INFO : EPOCH 1 - PROGRESS: at 35.83% examples, 232142 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:35,179 : INFO : EPOCH 1 - PROGRESS: at 39.33% examples, 233875 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-14 12:22:36,190 : INFO : EPOCH 1 - PROGRESS: at 43.03% examples, 236683 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:37,191 : INFO : EPOCH 1 - PROGRESS: at 46.44% examples, 237703 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:38,240 : INFO : EPOCH 1 - PROGRESS: at 50.03% examples, 238841 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:22:39,258 : INFO : EPOCH 1 - PROGRESS: at 53.64% examples, 240297 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:22:40,275 : INFO : EPOCH 1 - PROGRESS: at 57.25% examples, 241592 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:41,318 : INFO : EPOCH 1 - PROGRESS: at 60.97% examples, 242817 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:42,374 : INFO : EPOCH 1 - PROGRESS: at 64.26% examples, 242221 words/s, in_qsize 5, out_qsize 2\n",
      "2019-05-14 12:22:43,384 : INFO : EPOCH 1 - PROGRESS: at 66.97% examples, 240064 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:44,441 : INFO : EPOCH 1 - PROGRESS: at 69.49% examples, 236921 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:45,482 : INFO : EPOCH 1 - PROGRESS: at 71.90% examples, 233903 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:22:46,552 : INFO : EPOCH 1 - PROGRESS: at 74.91% examples, 232737 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:22:47,612 : INFO : EPOCH 1 - PROGRESS: at 77.02% examples, 229078 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:48,713 : INFO : EPOCH 1 - PROGRESS: at 79.92% examples, 227650 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:22:49,800 : INFO : EPOCH 1 - PROGRESS: at 82.74% examples, 226363 words/s, in_qsize 5, out_qsize 1\n",
      "2019-05-14 12:22:50,803 : INFO : EPOCH 1 - PROGRESS: at 84.94% examples, 223908 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:51,825 : INFO : EPOCH 1 - PROGRESS: at 87.56% examples, 222685 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:52,855 : INFO : EPOCH 1 - PROGRESS: at 90.07% examples, 221226 words/s, in_qsize 5, out_qsize 2\n",
      "2019-05-14 12:22:53,862 : INFO : EPOCH 1 - PROGRESS: at 92.87% examples, 220741 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:54,901 : INFO : EPOCH 1 - PROGRESS: at 95.78% examples, 220286 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-14 12:22:55,961 : INFO : EPOCH 1 - PROGRESS: at 98.87% examples, 220171 words/s, in_qsize 5, out_qsize 2\n",
      "2019-05-14 12:22:56,226 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-14 12:22:56,246 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-14 12:22:56,257 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-14 12:22:56,264 : INFO : EPOCH - 1 : training on 9963360 raw words (7395026 effective words) took 33.5s, 220640 effective words/s\n",
      "2019-05-14 12:22:57,298 : INFO : EPOCH 2 - PROGRESS: at 2.30% examples, 170592 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:58,329 : INFO : EPOCH 2 - PROGRESS: at 5.09% examples, 186119 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:22:59,332 : INFO : EPOCH 2 - PROGRESS: at 7.31% examples, 178443 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:00,368 : INFO : EPOCH 2 - PROGRESS: at 10.32% examples, 187612 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:01,424 : INFO : EPOCH 2 - PROGRESS: at 13.13% examples, 189507 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:02,471 : INFO : EPOCH 2 - PROGRESS: at 15.84% examples, 189807 words/s, in_qsize 5, out_qsize 2\n",
      "2019-05-14 12:23:03,526 : INFO : EPOCH 2 - PROGRESS: at 18.96% examples, 193898 words/s, in_qsize 3, out_qsize 2\n",
      "2019-05-14 12:23:04,553 : INFO : EPOCH 2 - PROGRESS: at 21.77% examples, 194945 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:05,621 : INFO : EPOCH 2 - PROGRESS: at 25.39% examples, 201282 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:23:06,643 : INFO : EPOCH 2 - PROGRESS: at 29.00% examples, 207218 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:07,654 : INFO : EPOCH 2 - PROGRESS: at 31.91% examples, 207686 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:08,667 : INFO : EPOCH 2 - PROGRESS: at 35.13% examples, 209848 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:09,689 : INFO : EPOCH 2 - PROGRESS: at 38.33% examples, 211559 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:10,750 : INFO : EPOCH 2 - PROGRESS: at 42.03% examples, 215000 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:11,794 : INFO : EPOCH 2 - PROGRESS: at 45.64% examples, 217735 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:12,831 : INFO : EPOCH 2 - PROGRESS: at 49.23% examples, 220215 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:13,858 : INFO : EPOCH 2 - PROGRESS: at 52.74% examples, 222124 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:14,895 : INFO : EPOCH 2 - PROGRESS: at 56.36% examples, 224117 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:15,911 : INFO : EPOCH 2 - PROGRESS: at 59.86% examples, 225738 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:16,959 : INFO : EPOCH 2 - PROGRESS: at 63.46% examples, 227214 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:23:17,962 : INFO : EPOCH 2 - PROGRESS: at 66.47% examples, 226959 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-14 12:23:19,000 : INFO : EPOCH 2 - PROGRESS: at 69.80% examples, 227377 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:23:20,069 : INFO : EPOCH 2 - PROGRESS: at 72.61% examples, 225879 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:21,084 : INFO : EPOCH 2 - PROGRESS: at 75.01% examples, 223805 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:22,092 : INFO : EPOCH 2 - PROGRESS: at 78.22% examples, 224265 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:23,131 : INFO : EPOCH 2 - PROGRESS: at 81.62% examples, 224976 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:24,147 : INFO : EPOCH 2 - PROGRESS: at 85.14% examples, 226096 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:25,160 : INFO : EPOCH 2 - PROGRESS: at 88.66% examples, 227161 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:26,210 : INFO : EPOCH 2 - PROGRESS: at 92.18% examples, 227860 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:27,232 : INFO : EPOCH 2 - PROGRESS: at 95.68% examples, 228717 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:28,242 : INFO : EPOCH 2 - PROGRESS: at 99.28% examples, 229835 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:28,418 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-14 12:23:28,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-14 12:23:28,473 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-14 12:23:28,474 : INFO : EPOCH - 2 : training on 9963360 raw words (7394969 effective words) took 32.2s, 229820 effective words/s\n",
      "2019-05-14 12:23:29,499 : INFO : EPOCH 3 - PROGRESS: at 3.20% examples, 234348 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:30,562 : INFO : EPOCH 3 - PROGRESS: at 6.90% examples, 246508 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:31,564 : INFO : EPOCH 3 - PROGRESS: at 10.42% examples, 250437 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:32,603 : INFO : EPOCH 3 - PROGRESS: at 13.63% examples, 244934 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:33,646 : INFO : EPOCH 3 - PROGRESS: at 16.74% examples, 240003 words/s, in_qsize 5, out_qsize 1\n",
      "2019-05-14 12:23:34,673 : INFO : EPOCH 3 - PROGRESS: at 19.36% examples, 231404 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:35,715 : INFO : EPOCH 3 - PROGRESS: at 22.08% examples, 225762 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:36,771 : INFO : EPOCH 3 - PROGRESS: at 25.00% examples, 222991 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:37,849 : INFO : EPOCH 3 - PROGRESS: at 27.99% examples, 221067 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:23:38,881 : INFO : EPOCH 3 - PROGRESS: at 31.11% examples, 221245 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:39,895 : INFO : EPOCH 3 - PROGRESS: at 34.23% examples, 221724 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:40,935 : INFO : EPOCH 3 - PROGRESS: at 37.33% examples, 221709 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:41,942 : INFO : EPOCH 3 - PROGRESS: at 40.23% examples, 221054 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:42,957 : INFO : EPOCH 3 - PROGRESS: at 43.13% examples, 220397 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:43,978 : INFO : EPOCH 3 - PROGRESS: at 45.94% examples, 219510 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:45,014 : INFO : EPOCH 3 - PROGRESS: at 49.13% examples, 219873 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:46,019 : INFO : EPOCH 3 - PROGRESS: at 51.84% examples, 218705 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-14 12:23:47,108 : INFO : EPOCH 3 - PROGRESS: at 54.85% examples, 217882 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:48,130 : INFO : EPOCH 3 - PROGRESS: at 58.05% examples, 218615 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:49,194 : INFO : EPOCH 3 - PROGRESS: at 61.07% examples, 218127 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:23:50,276 : INFO : EPOCH 3 - PROGRESS: at 64.36% examples, 218526 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:23:51,324 : INFO : EPOCH 3 - PROGRESS: at 67.37% examples, 218253 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:52,351 : INFO : EPOCH 3 - PROGRESS: at 70.19% examples, 217560 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:53,365 : INFO : EPOCH 3 - PROGRESS: at 73.51% examples, 218536 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:54,381 : INFO : EPOCH 3 - PROGRESS: at 76.82% examples, 219410 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:55,411 : INFO : EPOCH 3 - PROGRESS: at 79.72% examples, 219006 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:23:56,428 : INFO : EPOCH 3 - PROGRESS: at 82.53% examples, 218460 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-14 12:23:57,467 : INFO : EPOCH 3 - PROGRESS: at 85.74% examples, 218823 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:58,534 : INFO : EPOCH 3 - PROGRESS: at 89.06% examples, 219204 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:23:59,592 : INFO : EPOCH 3 - PROGRESS: at 92.17% examples, 219138 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:00,624 : INFO : EPOCH 3 - PROGRESS: at 95.28% examples, 219245 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:01,629 : INFO : EPOCH 3 - PROGRESS: at 98.28% examples, 219307 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:02,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-14 12:24:02,184 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-14 12:24:02,197 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-14 12:24:02,198 : INFO : EPOCH - 3 : training on 9963360 raw words (7394837 effective words) took 33.7s, 219361 effective words/s\n",
      "2019-05-14 12:24:03,234 : INFO : EPOCH 4 - PROGRESS: at 2.80% examples, 203587 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:04,237 : INFO : EPOCH 4 - PROGRESS: at 5.99% examples, 219949 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:05,249 : INFO : EPOCH 4 - PROGRESS: at 9.41% examples, 229526 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:06,280 : INFO : EPOCH 4 - PROGRESS: at 12.33% examples, 224167 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:07,281 : INFO : EPOCH 4 - PROGRESS: at 15.24% examples, 222457 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-14 12:24:08,365 : INFO : EPOCH 4 - PROGRESS: at 18.75% examples, 225473 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:09,373 : INFO : EPOCH 4 - PROGRESS: at 22.18% examples, 228962 words/s, in_qsize 5, out_qsize 1\n",
      "2019-05-14 12:24:10,388 : INFO : EPOCH 4 - PROGRESS: at 25.69% examples, 232326 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:11,439 : INFO : EPOCH 4 - PROGRESS: at 29.10% examples, 233214 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:12,442 : INFO : EPOCH 4 - PROGRESS: at 32.62% examples, 235719 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:13,479 : INFO : EPOCH 4 - PROGRESS: at 35.43% examples, 232413 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:14,480 : INFO : EPOCH 4 - PROGRESS: at 37.63% examples, 226768 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:15,556 : INFO : EPOCH 4 - PROGRESS: at 40.33% examples, 223478 words/s, in_qsize 4, out_qsize 2\n",
      "2019-05-14 12:24:16,572 : INFO : EPOCH 4 - PROGRESS: at 42.93% examples, 221122 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:17,591 : INFO : EPOCH 4 - PROGRESS: at 45.94% examples, 220934 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:18,598 : INFO : EPOCH 4 - PROGRESS: at 49.04% examples, 221356 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:24:19,611 : INFO : EPOCH 4 - PROGRESS: at 52.14% examples, 221691 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:20,694 : INFO : EPOCH 4 - PROGRESS: at 55.25% examples, 221165 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:24:21,699 : INFO : EPOCH 4 - PROGRESS: at 58.35% examples, 221568 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:22,717 : INFO : EPOCH 4 - PROGRESS: at 61.57% examples, 222118 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:23,728 : INFO : EPOCH 4 - PROGRESS: at 64.16% examples, 220658 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:24,750 : INFO : EPOCH 4 - PROGRESS: at 66.87% examples, 219558 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:25,770 : INFO : EPOCH 4 - PROGRESS: at 69.19% examples, 217295 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:26,791 : INFO : EPOCH 4 - PROGRESS: at 72.00% examples, 216726 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-14 12:24:27,793 : INFO : EPOCH 4 - PROGRESS: at 74.41% examples, 215198 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:28,811 : INFO : EPOCH 4 - PROGRESS: at 77.33% examples, 215051 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:29,823 : INFO : EPOCH 4 - PROGRESS: at 80.32% examples, 215221 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:30,839 : INFO : EPOCH 4 - PROGRESS: at 83.24% examples, 215084 words/s, in_qsize 5, out_qsize 2\n",
      "2019-05-14 12:24:31,867 : INFO : EPOCH 4 - PROGRESS: at 86.04% examples, 214639 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:32,956 : INFO : EPOCH 4 - PROGRESS: at 88.36% examples, 212603 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-14 12:24:33,957 : INFO : EPOCH 4 - PROGRESS: at 90.68% examples, 211273 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:34,991 : INFO : EPOCH 4 - PROGRESS: at 93.57% examples, 211162 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:36,013 : INFO : EPOCH 4 - PROGRESS: at 96.27% examples, 210692 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:37,050 : INFO : EPOCH 4 - PROGRESS: at 99.68% examples, 211650 words/s, in_qsize 3, out_qsize 1\n",
      "2019-05-14 12:24:37,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-14 12:24:37,077 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-14 12:24:37,134 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-14 12:24:37,139 : INFO : EPOCH - 4 : training on 9963360 raw words (7396271 effective words) took 34.9s, 211770 effective words/s\n",
      "2019-05-14 12:24:38,181 : INFO : EPOCH 5 - PROGRESS: at 3.20% examples, 235124 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:39,195 : INFO : EPOCH 5 - PROGRESS: at 6.40% examples, 234471 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:40,203 : INFO : EPOCH 5 - PROGRESS: at 9.71% examples, 237317 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:41,205 : INFO : EPOCH 5 - PROGRESS: at 12.93% examples, 237232 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:42,229 : INFO : EPOCH 5 - PROGRESS: at 15.64% examples, 228844 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:43,229 : INFO : EPOCH 5 - PROGRESS: at 18.65% examples, 227791 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:44,260 : INFO : EPOCH 5 - PROGRESS: at 21.88% examples, 228163 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:45,279 : INFO : EPOCH 5 - PROGRESS: at 24.29% examples, 221460 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:46,296 : INFO : EPOCH 5 - PROGRESS: at 27.19% examples, 220317 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:47,338 : INFO : EPOCH 5 - PROGRESS: at 30.21% examples, 219654 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:48,425 : INFO : EPOCH 5 - PROGRESS: at 33.02% examples, 216907 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:49,460 : INFO : EPOCH 5 - PROGRESS: at 35.43% examples, 213114 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:24:50,500 : INFO : EPOCH 5 - PROGRESS: at 38.54% examples, 213743 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:51,546 : INFO : EPOCH 5 - PROGRESS: at 41.53% examples, 213678 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:52,563 : INFO : EPOCH 5 - PROGRESS: at 44.74% examples, 214958 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:53,568 : INFO : EPOCH 5 - PROGRESS: at 47.73% examples, 215332 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:54,613 : INFO : EPOCH 5 - PROGRESS: at 50.53% examples, 214360 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:55,648 : INFO : EPOCH 5 - PROGRESS: at 53.44% examples, 213995 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:56,691 : INFO : EPOCH 5 - PROGRESS: at 56.36% examples, 213583 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:24:57,696 : INFO : EPOCH 5 - PROGRESS: at 59.15% examples, 213223 words/s, in_qsize 6, out_qsize 1\n",
      "2019-05-14 12:24:58,710 : INFO : EPOCH 5 - PROGRESS: at 61.97% examples, 212839 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:24:59,733 : INFO : EPOCH 5 - PROGRESS: at 64.97% examples, 213040 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:00,743 : INFO : EPOCH 5 - PROGRESS: at 67.77% examples, 212726 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:25:01,804 : INFO : EPOCH 5 - PROGRESS: at 70.59% examples, 211998 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:02,804 : INFO : EPOCH 5 - PROGRESS: at 73.21% examples, 211251 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:03,827 : INFO : EPOCH 5 - PROGRESS: at 76.32% examples, 211762 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:04,831 : INFO : EPOCH 5 - PROGRESS: at 79.32% examples, 212118 words/s, in_qsize 4, out_qsize 1\n",
      "2019-05-14 12:25:05,834 : INFO : EPOCH 5 - PROGRESS: at 82.13% examples, 211938 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:06,923 : INFO : EPOCH 5 - PROGRESS: at 85.14% examples, 211673 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:08,004 : INFO : EPOCH 5 - PROGRESS: at 88.46% examples, 212206 words/s, in_qsize 6, out_qsize 0\n",
      "2019-05-14 12:25:09,014 : INFO : EPOCH 5 - PROGRESS: at 91.48% examples, 212451 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:10,049 : INFO : EPOCH 5 - PROGRESS: at 94.38% examples, 212296 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:11,065 : INFO : EPOCH 5 - PROGRESS: at 97.17% examples, 212055 words/s, in_qsize 5, out_qsize 0\n",
      "2019-05-14 12:25:11,980 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-14 12:25:11,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-14 12:25:12,030 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-14 12:25:12,032 : INFO : EPOCH - 5 : training on 9963360 raw words (7395505 effective words) took 34.9s, 212155 effective words/s\n",
      "2019-05-14 12:25:12,034 : INFO : training on a 49816800 raw words (36976608 effective words) took 169.3s, 218415 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36976608, 49816800)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v = Word2Vec(size=n_dim, min_count=15)\n",
    "tweet_w2v.build_vocab(x_train)\n",
    "tweet_w2v.train(x_train,total_examples=tweet_w2v.corpus_count, epochs=5) #epoch=tweet_w2v.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18054, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whatis', 'and', 'when', 'is', 'shorties', 'me', 'nb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "worddict=dict()\n",
    "for x in tweet_w2v.wv.vocab.keys():\n",
    "    worddict[x]=tweet_w2v.wv.vocab[x].__dict__['index']\n",
    "# tweet_w2v.wv.vocab['kitkat'].__dict__['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'½c': 10282,\n",
       " 'hospital': 920,\n",
       " \"harper's\": 9013,\n",
       " 'tropical': 6712,\n",
       " 'atl': 2140,\n",
       " 'cocacola': 15865,\n",
       " 'everyones': 3508,\n",
       " 'goooood': 4021,\n",
       " 'sons': 6006,\n",
       " 'wasted': 2299,\n",
       " 'dos': 9918,\n",
       " 'completed': 3108,\n",
       " 'noir': 15972,\n",
       " 'insomnia': 2353,\n",
       " 'protector': 17291,\n",
       " 'loop': 4173,\n",
       " 'patricia': 16236,\n",
       " 'booo': 2070,\n",
       " 'fold': 9183,\n",
       " 'overs': 10142,\n",
       " 'buckle': 13377,\n",
       " 'sen': 14053,\n",
       " '½s': 2669,\n",
       " 'charging': 4669,\n",
       " 'downstairs': 3202,\n",
       " 'upside': 3971,\n",
       " 'transplant': 16173,\n",
       " 'hcc': 11764,\n",
       " 'volcano': 16888,\n",
       " 'conversion': 14669,\n",
       " 'taiwan': 9730,\n",
       " 'oct': 8301,\n",
       " 'composing': 17309,\n",
       " 'reasoning': 17548,\n",
       " \"momma's\": 13208,\n",
       " 'williams': 5231,\n",
       " 'bounty': 15902,\n",
       " 'prayed': 12164,\n",
       " 'meatloaf': 14189,\n",
       " 'southpark': 14825,\n",
       " 'sleeves': 12277,\n",
       " 'squish': 16708,\n",
       " 'dragging': 5241,\n",
       " 'gen': 4671,\n",
       " 'claim': 4918,\n",
       " 'kelley': 16709,\n",
       " 'obscure': 14609,\n",
       " 'dayyyy': 12953,\n",
       " 'woww': 11745,\n",
       " 'stupidest': 14943,\n",
       " 'wc': 9565,\n",
       " 'tonighti': 9954,\n",
       " 'unit': 4479,\n",
       " 'squares': 13992,\n",
       " 'ohno': 15697,\n",
       " 'makan': 10118,\n",
       " 'shelves': 11522,\n",
       " 'graduated': 2968,\n",
       " 'bumps': 11620,\n",
       " 'woohoo': 1424,\n",
       " 'spelt': 7467,\n",
       " 'commercials': 4633,\n",
       " 'beau': 9873,\n",
       " 'marketing': 2536,\n",
       " 'skittles': 6393,\n",
       " 'walker': 8064,\n",
       " 'sickest': 12514,\n",
       " 'burp': 16406,\n",
       " 'robot': 4989,\n",
       " 'finshed': 13541,\n",
       " 'dissapointed': 3878,\n",
       " 'mars': 5464,\n",
       " 'brother': 634,\n",
       " 'pierced': 6416,\n",
       " 'economics': 7301,\n",
       " 'himher': 15495,\n",
       " 'vans': 9440,\n",
       " 'alicia': 8908,\n",
       " 'drool': 8055,\n",
       " 'cigarettes': 7261,\n",
       " 'xxxxxxxxx': 14561,\n",
       " 'possibility': 7843,\n",
       " 'tshirt': 2196,\n",
       " 'doing': 174,\n",
       " 'invitation': 6000,\n",
       " 'probly': 7054,\n",
       " 'theam': 13078,\n",
       " 'complaints': 8710,\n",
       " 'zumba': 13562,\n",
       " 'domestic': 8696,\n",
       " 'wrkin': 16364,\n",
       " 'peggy': 16044,\n",
       " 'positively': 13418,\n",
       " 'trucks': 9100,\n",
       " 'ust': 11383,\n",
       " 'intervention': 9933,\n",
       " 'carrier': 9290,\n",
       " 'evo': 14404,\n",
       " 'toyota': 11911,\n",
       " 'sauna': 9566,\n",
       " 'downfall': 14645,\n",
       " 'venue': 4259,\n",
       " 'morn': 2803,\n",
       " 'interview': 1039,\n",
       " 'dairy': 5250,\n",
       " 'kirk': 8662,\n",
       " 'activate': 12348,\n",
       " 'loses': 6512,\n",
       " 'arrgh': 12972,\n",
       " 'labor': 6900,\n",
       " 'lingo': 11309,\n",
       " 'quitting': 7569,\n",
       " 'myyr': 10427,\n",
       " 'sep': 16318,\n",
       " 'ethics': 14405,\n",
       " 'men': 1267,\n",
       " 'neighbours': 3626,\n",
       " 'upstairs': 4837,\n",
       " 'nocturnal': 11507,\n",
       " 'fortunately': 6957,\n",
       " 'entirely': 5083,\n",
       " 'reunite': 16629,\n",
       " 'pay': 560,\n",
       " 'twitch': 16207,\n",
       " 'harder': 2235,\n",
       " 'heels': 2626,\n",
       " 'third': 1856,\n",
       " 'chipped': 8281,\n",
       " 'icon': 3146,\n",
       " 'dread': 7262,\n",
       " 'btwn': 13644,\n",
       " 'lotto': 9861,\n",
       " 'worthless': 9713,\n",
       " 'bootleg': 10437,\n",
       " 'en': 2926,\n",
       " 'bulaga': 16927,\n",
       " \"g'nite\": 5770,\n",
       " 'wo': 2134,\n",
       " 'column': 6513,\n",
       " 'closer': 1846,\n",
       " 'bath': 1511,\n",
       " 'smfh': 17032,\n",
       " 'macbook': 1859,\n",
       " 'kimi': 13015,\n",
       " 'winchester': 14376,\n",
       " 'eastern': 6024,\n",
       " 'laptop': 635,\n",
       " 'digs': 15561,\n",
       " 'answers': 3416,\n",
       " 'greattt': 15494,\n",
       " 'kool': 4700,\n",
       " 'planning': 1169,\n",
       " \"they'll\": 2001,\n",
       " 'copyright': 8207,\n",
       " 'itv': 7279,\n",
       " 'writing': 702,\n",
       " 'mequot': 2935,\n",
       " 'mirror': 4476,\n",
       " 'fraid': 13886,\n",
       " 'hairdresser': 8589,\n",
       " 'pinkberry': 7970,\n",
       " 'sleeeeep': 8409,\n",
       " 'advised': 16319,\n",
       " 'sibling': 14552,\n",
       " 'phonecall': 17591,\n",
       " 'hugely': 11999,\n",
       " 'clicked': 4550,\n",
       " 'eve': 3936,\n",
       " 'facility': 14785,\n",
       " 'pouts': 12017,\n",
       " 'drinkies': 16848,\n",
       " 'films': 3914,\n",
       " 'keypad': 17619,\n",
       " 'outnite': 17549,\n",
       " 'jane': 4661,\n",
       " 'sheila': 15544,\n",
       " 'baker': 10647,\n",
       " 'designated': 14182,\n",
       " 'spoiling': 12515,\n",
       " 'pumps': 11363,\n",
       " 'deja': 13742,\n",
       " 'predictable': 11977,\n",
       " 'kb': 13079,\n",
       " 'ooo': 2309,\n",
       " 'horray': 15632,\n",
       " 'absolute': 4319,\n",
       " 'italy': 2138,\n",
       " 'trinity': 13437,\n",
       " 'bloom': 9469,\n",
       " 'android': 5374,\n",
       " 'awakening': 11581,\n",
       " 'purty': 15361,\n",
       " 'permit': 8175,\n",
       " 'aboard': 8920,\n",
       " 'gas': 2152,\n",
       " 'inbetweeners': 16533,\n",
       " 'seth': 6533,\n",
       " 'able': 460,\n",
       " 'goal': 2365,\n",
       " 'milton': 12469,\n",
       " 'within': 2237,\n",
       " 'woof': 9743,\n",
       " 'bebo': 4876,\n",
       " 'thr': 8577,\n",
       " 'americans': 5855,\n",
       " 'hearts': 3588,\n",
       " 'interaction': 10019,\n",
       " 'possum': 12187,\n",
       " 'acronym': 17260,\n",
       " 'antonio': 5691,\n",
       " 'buggered': 11634,\n",
       " 'themselves': 3448,\n",
       " 'revealed': 11047,\n",
       " 'happenin': 11364,\n",
       " 'corp': 13887,\n",
       " \"mommy's\": 6633,\n",
       " 'launched': 6698,\n",
       " 'remotely': 11191,\n",
       " 'hybrid': 11993,\n",
       " 'database': 6499,\n",
       " 'wagon': 7972,\n",
       " 'beli': 13765,\n",
       " 'tetris': 3983,\n",
       " 'kidnap': 10814,\n",
       " 'brady': 11678,\n",
       " 'soaked': 3947,\n",
       " 'quotnot': 8334,\n",
       " 'kill': 917,\n",
       " 'chit': 13307,\n",
       " 'babysit': 4903,\n",
       " 'heartburn': 6455,\n",
       " 'waiting': 281,\n",
       " 'wound': 7527,\n",
       " 'resources': 9283,\n",
       " 'glasses': 1709,\n",
       " 'jazz': 3497,\n",
       " 'pi': 8488,\n",
       " 'ive': 645,\n",
       " 'luvin': 10162,\n",
       " 'coal': 18007,\n",
       " 'ferrari': 9001,\n",
       " 'adjust': 8413,\n",
       " 'place': 406,\n",
       " 'helpful': 3630,\n",
       " 'coz': 1116,\n",
       " 'crew': 2180,\n",
       " 'forced': 2937,\n",
       " 'thoo': 17226,\n",
       " 'handful': 12118,\n",
       " 'jen': 3450,\n",
       " 'notorious': 11703,\n",
       " 'flames': 10085,\n",
       " 'mare': 12709,\n",
       " 'checking': 1319,\n",
       " 'always': 189,\n",
       " 'strikes': 6816,\n",
       " 'syncing': 7760,\n",
       " 'cut': 627,\n",
       " 'zero': 3065,\n",
       " 'sniff': 2548,\n",
       " 'electrical': 9429,\n",
       " 'forms': 5373,\n",
       " 'toilets': 13605,\n",
       " 'lower': 3437,\n",
       " 'cheryl': 11471,\n",
       " 'actress': 5337,\n",
       " 'plotting': 16531,\n",
       " 'domination': 10690,\n",
       " 'quotwho': 12033,\n",
       " 'franz': 14954,\n",
       " 'sarah': 1900,\n",
       " 'iloveyou': 6674,\n",
       " 'keeping': 1308,\n",
       " 'effort': 3494,\n",
       " 'tayo': 13606,\n",
       " 'infamous': 5552,\n",
       " 'ho': 2604,\n",
       " 'try': 254,\n",
       " 'aspect': 11972,\n",
       " 'uh': 1419,\n",
       " 'fears': 9582,\n",
       " 'sunderland': 15211,\n",
       " 'pronounced': 12562,\n",
       " 'orientation': 5414,\n",
       " 'blinds': 11005,\n",
       " 'ehhh': 7593,\n",
       " 'fred': 4551,\n",
       " 'evar': 12895,\n",
       " 'louie': 12756,\n",
       " 'luis': 12532,\n",
       " 'dried': 6832,\n",
       " 'seventeen': 10778,\n",
       " 'bloated': 10295,\n",
       " 'shedding': 16076,\n",
       " 'serendipity': 12629,\n",
       " 'jb': 1586,\n",
       " 'pissin': 16276,\n",
       " 'unplug': 16951,\n",
       " 'orphan': 16803,\n",
       " 'dinosaur': 9893,\n",
       " 'dearly': 6689,\n",
       " 'suckssss': 17871,\n",
       " 'dungeon': 15166,\n",
       " 'sum': 1382,\n",
       " 'english': 694,\n",
       " 'lip': 2577,\n",
       " 'yawns': 10285,\n",
       " 'fever': 1123,\n",
       " 'crown': 7435,\n",
       " 'z': 4113,\n",
       " 'berlin': 3972,\n",
       " 'forcing': 6836,\n",
       " 'effect': 2905,\n",
       " 'entire': 1473,\n",
       " 'savvy': 13811,\n",
       " 'both': 437,\n",
       " 'hoops': 12099,\n",
       " 'stacks': 15362,\n",
       " 'whole': 424,\n",
       " 'wu': 9647,\n",
       " \"i'll\": 120,\n",
       " 'transfer': 4397,\n",
       " 'overrated': 7225,\n",
       " 'flopped': 16077,\n",
       " 'stateside': 14276,\n",
       " 'system': 1513,\n",
       " 'zzzzzz': 12999,\n",
       " 'main': 2083,\n",
       " 'happening': 1379,\n",
       " 'unintentionally': 17148,\n",
       " 'merely': 15728,\n",
       " 'accidently': 5747,\n",
       " 'fractured': 12056,\n",
       " 'pra': 11635,\n",
       " 'awwwe': 15113,\n",
       " 'armed': 11365,\n",
       " 'paws': 10125,\n",
       " 'unique': 4838,\n",
       " '\\x82': 948,\n",
       " 'uncomfortable': 4703,\n",
       " 'disconnect': 14109,\n",
       " 'folks': 1432,\n",
       " 'monty': 13258,\n",
       " 'colour': 2909,\n",
       " 'june': 744,\n",
       " 'lying': 2133,\n",
       " 'veg': 6265,\n",
       " 'biking': 5084,\n",
       " 'quotdont': 14194,\n",
       " 'glass': 1556,\n",
       " 'caffiene': 16361,\n",
       " 'beers': 3483,\n",
       " 'worker': 8407,\n",
       " 'commented': 5575,\n",
       " 'unreliable': 17149,\n",
       " '\\x86': 3102,\n",
       " 'mii': 7768,\n",
       " 'waits': 8859,\n",
       " 'mannn': 6707,\n",
       " 'happyth': 4620,\n",
       " 'owh': 15208,\n",
       " 'chords': 14005,\n",
       " 'mission': 2543,\n",
       " 'dã': 11582,\n",
       " 'overcast': 4606,\n",
       " 'offended': 6362,\n",
       " 'angela': 7319,\n",
       " 'goose': 5764,\n",
       " 'color': 1713,\n",
       " 'glimpse': 11733,\n",
       " 'hottt': 13975,\n",
       " 'asos': 14355,\n",
       " 'hacked': 3710,\n",
       " 'chi': 4030,\n",
       " 'fees': 7945,\n",
       " 'noone': 2552,\n",
       " 'goin': 610,\n",
       " 'mags': 10312,\n",
       " 'oysters': 15729,\n",
       " 'adelaide': 7681,\n",
       " 'quiet': 1238,\n",
       " 'olives': 13594,\n",
       " 'status': 1848,\n",
       " 'dayum': 11747,\n",
       " 'munich': 8893,\n",
       " 'worcester': 17686,\n",
       " 'tum': 10903,\n",
       " 'agian': 11168,\n",
       " 'very': 115,\n",
       " 'neighbourhood': 13051,\n",
       " 'cinderella': 7864,\n",
       " 'passive': 16242,\n",
       " 'tash': 14406,\n",
       " 'beyonce': 4191,\n",
       " 'already': 190,\n",
       " 'noww': 6788,\n",
       " 'cannot': 770,\n",
       " 'clashes': 17636,\n",
       " 'cello': 16997,\n",
       " 'mental': 3459,\n",
       " 'packages': 8070,\n",
       " 'marathon': 1622,\n",
       " 'herr': 13290,\n",
       " 'trips': 3843,\n",
       " 'feeder': 15114,\n",
       " 'dear': 625,\n",
       " 'period': 2390,\n",
       " 'aunts': 6752,\n",
       " 'urs': 4896,\n",
       " 'ashlee': 13475,\n",
       " 'beth': 4821,\n",
       " 'frap': 14980,\n",
       " 'familyforce': 15082,\n",
       " '½o': 6490,\n",
       " 'twiggas': 9511,\n",
       " 'bulb': 12815,\n",
       " 'std': 16804,\n",
       " 'quotlove': 8594,\n",
       " \"o's\": 12463,\n",
       " 'poopie': 16327,\n",
       " 'powers': 5127,\n",
       " 'logs': 15698,\n",
       " 'distracting': 7075,\n",
       " 'brussels': 14310,\n",
       " 'urghhh': 16074,\n",
       " 'hgtv': 15746,\n",
       " 'warming': 5317,\n",
       " 'apartment': 1602,\n",
       " 'buddies': 3268,\n",
       " 'eternally': 15973,\n",
       " 'hahhaha': 11824,\n",
       " 'baaaad': 16243,\n",
       " 'sections': 11789,\n",
       " 'forgot': 456,\n",
       " 'naa': 11061,\n",
       " 'bears': 4262,\n",
       " 'berkeley': 13324,\n",
       " 'tire': 3584,\n",
       " 'daynight': 8363,\n",
       " 'dodgers': 5432,\n",
       " 'venus': 14724,\n",
       " 'forums': 4293,\n",
       " 'limits': 6896,\n",
       " 'straightforward': 15209,\n",
       " 'turnoffwords': 11190,\n",
       " 'treat': 2429,\n",
       " 'eddings': 15083,\n",
       " 'flipflop': 17956,\n",
       " 'onlypm': 13859,\n",
       " 'merge': 13335,\n",
       " 'energy': 1446,\n",
       " 'hangoverquot': 12834,\n",
       " 'browser': 3537,\n",
       " 'detailed': 12570,\n",
       " 'cuzins': 16665,\n",
       " 'between': 1049,\n",
       " 'ducks': 5141,\n",
       " 'pleaseee': 5906,\n",
       " 'pk': 10447,\n",
       " 'panicked': 17108,\n",
       " 'webb': 14054,\n",
       " 'qood': 14465,\n",
       " 'twitches': 11537,\n",
       " 'forecast': 3650,\n",
       " 'disturbing': 6236,\n",
       " 'debris': 17592,\n",
       " 'shadow': 6562,\n",
       " 'elijah': 15312,\n",
       " 'laggy': 16078,\n",
       " 'announcing': 10658,\n",
       " 'location': 3121,\n",
       " 'kn': 13146,\n",
       " 'wiff': 6013,\n",
       " 'blessed': 1728,\n",
       " 'too': 41,\n",
       " 'majors': 17261,\n",
       " 'dissing': 17262,\n",
       " 'cancelling': 10466,\n",
       " 'lavender': 12729,\n",
       " 'antisocial': 14850,\n",
       " 'hahahha': 7373,\n",
       " 'sadie': 11903,\n",
       " 'adoption': 11244,\n",
       " 'shirtless': 9512,\n",
       " 'straighten': 6747,\n",
       " 'swimmin': 12518,\n",
       " 'presume': 15344,\n",
       " 'cheek': 5602,\n",
       " 'faced': 11128,\n",
       " 'chilling': 1685,\n",
       " 'attack': 2073,\n",
       " 'mullet': 12870,\n",
       " 'regarding': 5892,\n",
       " 'anh': 8624,\n",
       " 'streaks': 17624,\n",
       " 'venues': 16889,\n",
       " 'skirt': 4157,\n",
       " \"kevin's\": 16453,\n",
       " \"gov't\": 15132,\n",
       " 'qampa': 14356,\n",
       " 'vomiting': 9759,\n",
       " 'yehey': 14921,\n",
       " 'soooooooo': 4311,\n",
       " 'dinosaurs': 15224,\n",
       " 'nighters': 14944,\n",
       " 'later': 277,\n",
       " 'chains': 13357,\n",
       " 'slices': 11282,\n",
       " 'implementation': 16630,\n",
       " 'loong': 9465,\n",
       " 'catering': 13604,\n",
       " 'quicker': 7213,\n",
       " 'hmmi': 13610,\n",
       " 'lovato': 4563,\n",
       " 'fund': 8349,\n",
       " 'swap': 5149,\n",
       " 'previews': 8499,\n",
       " 'observation': 15013,\n",
       " 'windows': 1185,\n",
       " \"why'd\": 7964,\n",
       " 'sonic': 3827,\n",
       " 'deleted': 1884,\n",
       " 'cinnamon': 5117,\n",
       " 'seein': 5669,\n",
       " 'designers': 7999,\n",
       " 'carter': 8777,\n",
       " 'several': 2216,\n",
       " 'shield': 12778,\n",
       " 'nicer': 3926,\n",
       " 'ole': 4818,\n",
       " 'buffalo': 5204,\n",
       " 'grrrr': 2871,\n",
       " 'bcoz': 12533,\n",
       " 'soooo': 600,\n",
       " 'nik': 16952,\n",
       " 'byee': 5638,\n",
       " 'eugene': 14195,\n",
       " 'cã³': 10194,\n",
       " 'marshmellows': 15822,\n",
       " 'trippy': 14110,\n",
       " 'nuit': 15167,\n",
       " 'vacuum': 7124,\n",
       " 'cutie': 3463,\n",
       " 'tlc': 8073,\n",
       " 'massively': 11994,\n",
       " 'daysi': 15483,\n",
       " 'smooth': 4044,\n",
       " 'milkshakes': 12959,\n",
       " 'shorten': 14225,\n",
       " \"site's\": 16321,\n",
       " 'blahhhh': 11022,\n",
       " 'recovery': 3956,\n",
       " 'twitterberry': 3618,\n",
       " 'catalyst': 16407,\n",
       " 'monopoly': 7236,\n",
       " 'shrug': 13097,\n",
       " 'dee': 5183,\n",
       " 'ohand': 17401,\n",
       " 'alllllll': 12449,\n",
       " 'essay': 1682,\n",
       " 'shiny': 3070,\n",
       " 'relay': 4877,\n",
       " 'quoti': 1439,\n",
       " 'checked': 1389,\n",
       " 'wet': 1241,\n",
       " 'boiler': 16185,\n",
       " 'lawl': 11142,\n",
       " 'length': 7572,\n",
       " 'funky': 4889,\n",
       " 'warm': 838,\n",
       " 'steaming': 15139,\n",
       " 'reece': 16849,\n",
       " 'native': 8194,\n",
       " 'seeking': 10021,\n",
       " 'panasonic': 16890,\n",
       " 'fui': 17355,\n",
       " 'zit': 16409,\n",
       " 'wig': 9253,\n",
       " 'ridin': 11869,\n",
       " 'gooood': 3526,\n",
       " 'seek': 6682,\n",
       " 'canï': 8885,\n",
       " 'tracked': 16075,\n",
       " \"mama's\": 8742,\n",
       " 'prime': 6025,\n",
       " 'brody': 11204,\n",
       " 'dayss': 11748,\n",
       " 'beverages': 16805,\n",
       " 'awesome': 157,\n",
       " 'changs': 13255,\n",
       " 'trans': 17886,\n",
       " 'before': 214,\n",
       " 'snoring': 5371,\n",
       " 'graduate': 2524,\n",
       " 'openings': 14314,\n",
       " 'aaand': 10238,\n",
       " 'missin': 2049,\n",
       " 'panicking': 14922,\n",
       " \"body's\": 13888,\n",
       " 'qik': 13854,\n",
       " 'cramming': 8909,\n",
       " 'batter': 11604,\n",
       " 'counter': 4874,\n",
       " 'pork': 4327,\n",
       " 'girlie': 3866,\n",
       " 'syracuse': 13831,\n",
       " 'elite': 11086,\n",
       " 'cc': 5050,\n",
       " 'inconvenient': 13520,\n",
       " 'ù': 1472,\n",
       " 'jumpin': 17402,\n",
       " 'rising': 6753,\n",
       " 'quite': 515,\n",
       " 'buzzing': 8974,\n",
       " 'detail': 7783,\n",
       " 'tattoo': 2004,\n",
       " 'true': 447,\n",
       " \"how've\": 10612,\n",
       " 'prop': 9400,\n",
       " 'flowing': 9543,\n",
       " 'partake': 16850,\n",
       " 'soooon': 10662,\n",
       " \"katie's\": 15496,\n",
       " 'hmv': 9837,\n",
       " 'toni': 11790,\n",
       " 'cardigan': 11074,\n",
       " 'gainesville': 17868,\n",
       " 'rachael': 15298,\n",
       " 'md': 5104,\n",
       " 'services': 3698,\n",
       " 'uni': 1490,\n",
       " 'parking': 2439,\n",
       " 'compensate': 14670,\n",
       " 'plurking': 16365,\n",
       " 'ign': 17496,\n",
       " 'msg': 2711,\n",
       " 'treating': 4819,\n",
       " 'awwh': 7702,\n",
       " 'outline': 10391,\n",
       " 'crappy': 1368,\n",
       " 'reason': 657,\n",
       " 'quotsorry': 17913,\n",
       " 'swag': 6435,\n",
       " 'individual': 9312,\n",
       " 'flexible': 11825,\n",
       " 'fucks': 10344,\n",
       " 'org': 11771,\n",
       " 'banter': 9986,\n",
       " 'yesss': 2999,\n",
       " 'backups': 11165,\n",
       " 'babyyyy': 17617,\n",
       " 'gates': 10033,\n",
       " 'desks': 17454,\n",
       " 'sir': 1701,\n",
       " 'clinton': 13939,\n",
       " 'controllers': 16851,\n",
       " 'spec': 9627,\n",
       " 'mole': 12306,\n",
       " 'rochester': 10832,\n",
       " 'tidying': 5860,\n",
       " 'aussie': 3679,\n",
       " 'dishes': 2859,\n",
       " 'alison': 11735,\n",
       " 'sneezes': 15756,\n",
       " 'interactive': 11843,\n",
       " 'tooth': 2076,\n",
       " 'involved': 3036,\n",
       " 'al': 2473,\n",
       " 'armor': 14750,\n",
       " 'tale': 9039,\n",
       " 'lyrical': 17310,\n",
       " 'equivalent': 11292,\n",
       " 'approval': 7479,\n",
       " 'gahhhh': 13784,\n",
       " 'aaa': 7715,\n",
       " 'wal': 13143,\n",
       " 'critical': 7858,\n",
       " 'antm': 10490,\n",
       " 'crusty': 14982,\n",
       " 'birfday': 15449,\n",
       " 'crack': 2211,\n",
       " 'aging': 13521,\n",
       " 'jerks': 8576,\n",
       " 'niley': 5008,\n",
       " 'eated': 17366,\n",
       " 'rejection': 10493,\n",
       " 'colby': 12464,\n",
       " 'shaundiviney': 11647,\n",
       " 'boredddd': 12696,\n",
       " 'sank': 16085,\n",
       " 'afterwards': 3153,\n",
       " 'sole': 14056,\n",
       " 'ere': 10108,\n",
       " 'threads': 11955,\n",
       " 'txting': 8558,\n",
       " 'giv': 14708,\n",
       " 'arrows': 16953,\n",
       " 'mob': 9567,\n",
       " 'ppls': 8846,\n",
       " 'messaged': 10034,\n",
       " 'textt': 16142,\n",
       " 'blended': 16244,\n",
       " 'otay': 15475,\n",
       " 'freaken': 11405,\n",
       " 'drivin': 6901,\n",
       " 'clips': 5677,\n",
       " 'todaynot': 13860,\n",
       " 'purring': 15084,\n",
       " 'jaw': 5165,\n",
       " 'quotyou': 2728,\n",
       " 'blissful': 14340,\n",
       " 'global': 4239,\n",
       " 'vibes': 4087,\n",
       " 'lemsip': 15526,\n",
       " 'naps': 4929,\n",
       " 'lahat': 14983,\n",
       " 'oooo': 3887,\n",
       " 'queensland': 10997,\n",
       " 'vanessa': 5472,\n",
       " 'regent': 15323,\n",
       " 'sookie': 12704,\n",
       " 'oak': 8717,\n",
       " 'up': 28,\n",
       " 'stamps': 12100,\n",
       " 'surfin': 13409,\n",
       " 'whoops': 4940,\n",
       " 'gay': 1183,\n",
       " 'hang': 668,\n",
       " 'filmed': 8373,\n",
       " 'secondary': 13120,\n",
       " 'furnace': 16175,\n",
       " 'ox': 9965,\n",
       " 'statue': 15235,\n",
       " 'nowand': 12144,\n",
       " 'receptionist': 16736,\n",
       " 'slacking': 7267,\n",
       " 'flower': 3781,\n",
       " 'hahh': 17801,\n",
       " 'rappers': 17643,\n",
       " 'campfire': 13832,\n",
       " 'sudah': 17375,\n",
       " 'dominos': 13794,\n",
       " 'afraid': 1313,\n",
       " 'ffs': 5360,\n",
       " 'heartache': 12793,\n",
       " 'ako': 3729,\n",
       " 'wating': 13325,\n",
       " 'bec': 8378,\n",
       " 'argos': 15332,\n",
       " 'pregnancy': 8469,\n",
       " 'strong': 1591,\n",
       " 'invest': 9430,\n",
       " 'eligible': 10035,\n",
       " 'chess': 9643,\n",
       " 'dk': 8083,\n",
       " 'deffo': 6847,\n",
       " 'nuthin': 7084,\n",
       " 'covers': 4613,\n",
       " 'leigh': 13623,\n",
       " 'davina': 16187,\n",
       " 'kirsty': 16037,\n",
       " 'circa': 13098,\n",
       " 'ladies': 1327,\n",
       " 'excercise': 15063,\n",
       " 'completely': 1015,\n",
       " 'programs': 5362,\n",
       " 'ferret': 14502,\n",
       " 'sears': 15413,\n",
       " 'lake': 1398,\n",
       " 'sunburns': 13158,\n",
       " 'outquot': 7973,\n",
       " 'bai': 14377,\n",
       " 'fundraiser': 9534,\n",
       " 'advertised': 14731,\n",
       " 'amusing': 4496,\n",
       " 'licking': 10392,\n",
       " \"quotcan't\": 14030,\n",
       " 'sandy': 8448,\n",
       " 'taste': 1273,\n",
       " 'sfo': 10945,\n",
       " 'tyra': 10260,\n",
       " 'aloe': 9408,\n",
       " 'nordstrom': 17463,\n",
       " 'tonight': 119,\n",
       " 'social': 1476,\n",
       " 'designing': 5842,\n",
       " 'canvas': 9535,\n",
       " 'costing': 16177,\n",
       " 'favourites': 8184,\n",
       " 'sisters': 1666,\n",
       " 'flight': 778,\n",
       " 'ease': 7553,\n",
       " 'fee': 5190,\n",
       " 'fortunate': 11886,\n",
       " \"wendy's\": 8422,\n",
       " 'chef': 4154,\n",
       " 'talent': 1779,\n",
       " 'titles': 8822,\n",
       " 'cheerleading': 9928,\n",
       " 'regional': 14164,\n",
       " 'gong': 15757,\n",
       " 'tau': 11978,\n",
       " 'darwin': 17694,\n",
       " 'cubs': 5028,\n",
       " 'waterfront': 15085,\n",
       " \"leno's\": 8308,\n",
       " 'bro': 1008,\n",
       " 'seaside': 10311,\n",
       " 'revision': 998,\n",
       " 'whilst': 2501,\n",
       " 'home': 78,\n",
       " 'htc': 7346,\n",
       " 'wink': 4512,\n",
       " 'boobies': 9966,\n",
       " 'wuu': 16042,\n",
       " 'appetite': 8338,\n",
       " 'seesmic': 6945,\n",
       " 'ant': 4780,\n",
       " 'sickness': 3743,\n",
       " 'televised': 16532,\n",
       " 'laker': 3806,\n",
       " 'races': 5136,\n",
       " 'buisness': 13761,\n",
       " 'quid': 9080,\n",
       " 'heading': 556,\n",
       " 'stressin': 16359,\n",
       " '¤': 2187,\n",
       " 'ê²': 14064,\n",
       " 'gem': 8778,\n",
       " 'sessions': 4565,\n",
       " 'admission': 16593,\n",
       " 'jenn': 7136,\n",
       " 'afteram': 11925,\n",
       " 'susan': 1815,\n",
       " 'loren': 17403,\n",
       " 'awww': 461,\n",
       " 'texting': 2113,\n",
       " 'immediate': 15597,\n",
       " 'honoured': 11749,\n",
       " 'early': 233,\n",
       " 'applebees': 9717,\n",
       " 'scooter': 7285,\n",
       " 'qualities': 17562,\n",
       " 'rotterdam': 13080,\n",
       " 'pointer': 15562,\n",
       " 'frank': 4405,\n",
       " 'pack': 1320,\n",
       " 'bum': 2964,\n",
       " 'deli': 8732,\n",
       " 'ultrasnw': 14725,\n",
       " 'employer': 13052,\n",
       " 'morrissey': 12935,\n",
       " 'grudge': 16739,\n",
       " 'peer': 10099,\n",
       " 'gtgt': 4248,\n",
       " 'cocktail': 6010,\n",
       " 'bmw': 8231,\n",
       " 'mr': 855,\n",
       " 'tucson': 11406,\n",
       " 'bypm': 10222,\n",
       " 'yap': 17109,\n",
       " 'buffering': 17920,\n",
       " 'hail': 4805,\n",
       " 'hmmmmm': 6541,\n",
       " 'fraud': 13236,\n",
       " 'eventually': 2917,\n",
       " 'tru': 7617,\n",
       " 'stretched': 13099,\n",
       " 'pigeons': 13232,\n",
       " 'warped': 3052,\n",
       " 'image': 2310,\n",
       " 'awwe': 10901,\n",
       " 'savings': 8938,\n",
       " 'alls': 16423,\n",
       " 'eliza': 17455,\n",
       " 'aree': 12119,\n",
       " 'newsletter': 6511,\n",
       " 'fall': 682,\n",
       " 'ski': 11246,\n",
       " 'bien': 13275,\n",
       " 'smelling': 6427,\n",
       " 'avoid': 2628,\n",
       " 'licence': 9584,\n",
       " 'request': 2225,\n",
       " 'molly': 5095,\n",
       " 'mps': 10027,\n",
       " 'lr': 5485,\n",
       " 'twittercom': 11888,\n",
       " 'wifey': 3773,\n",
       " 'mets': 6842,\n",
       " 'prosper': 11283,\n",
       " 'everything': 377,\n",
       " 'staring': 3500,\n",
       " 'foot': 1255,\n",
       " 'fkin': 15086,\n",
       " 'sr': 10728,\n",
       " 'mediocre': 12962,\n",
       " 'besides': 2103,\n",
       " 'saved': 1996,\n",
       " 'navy': 6365,\n",
       " 'greatly': 5041,\n",
       " 'y': 801,\n",
       " 'tryout': 16631,\n",
       " 'koolaid': 13976,\n",
       " 'bmore': 10946,\n",
       " 'ann': 5701,\n",
       " 'square': 3018,\n",
       " \"morning's\": 15563,\n",
       " 'bearable': 16928,\n",
       " 'tune': 2284,\n",
       " 'scotty': 9701,\n",
       " 'fenway': 10869,\n",
       " 'operations': 17034,\n",
       " 'todayit': 17499,\n",
       " 'insomniac': 8972,\n",
       " 'liat': 11166,\n",
       " 'curves': 14694,\n",
       " 'funfilled': 16852,\n",
       " 'ringtone': 7450,\n",
       " 'champagne': 5033,\n",
       " 'signed': 1674,\n",
       " 'pff': 12468,\n",
       " 'vegemite': 12091,\n",
       " 'played': 887,\n",
       " 'pixie': 9041,\n",
       " 'appear': 3456,\n",
       " 'welcome': 372,\n",
       " 'whack': 6719,\n",
       " 'momma': 2693,\n",
       " 'airs': 12963,\n",
       " 'steaks': 9874,\n",
       " 'paintings': 11295,\n",
       " 'robs': 17695,\n",
       " 'runway': 9554,\n",
       " 'resorted': 16213,\n",
       " 'august': 1579,\n",
       " 'pepper': 4092,\n",
       " 'k': 1028,\n",
       " 'afterward': 11085,\n",
       " 'excitement': 3504,\n",
       " 'ich': 6748,\n",
       " 'migrate': 14984,\n",
       " 'mornin': 1625,\n",
       " 'shenanigans': 15786,\n",
       " 'buddhist': 17749,\n",
       " \"that'll\": 3015,\n",
       " 'mojo': 7872,\n",
       " 'alt': 9809,\n",
       " 'os': 1629,\n",
       " 'goosebumps': 12101,\n",
       " 'jetlag': 9702,\n",
       " 'owe': 3420,\n",
       " 'pet': 2160,\n",
       " 'perspective': 7159,\n",
       " 'notice': 1691,\n",
       " 'if': 66,\n",
       " 'situation': 2247,\n",
       " \"u're\": 3457,\n",
       " 'ohhhh': 3127,\n",
       " 'lautner': 6749,\n",
       " 'unexpected': 4498,\n",
       " 'sucha': 8804,\n",
       " 'barney': 11791,\n",
       " 'howz': 13685,\n",
       " 'deposit': 8539,\n",
       " 'anonymous': 14007,\n",
       " 'tokio': 7281,\n",
       " 'vac': 17200,\n",
       " 'merry': 10601,\n",
       " 'championships': 16762,\n",
       " 'emerge': 15633,\n",
       " 'tã': 7628,\n",
       " 'goth': 11178,\n",
       " 'pg': 6534,\n",
       " 'america': 1508,\n",
       " 'rg': 12355,\n",
       " 'neglect': 16009,\n",
       " 'heavens': 9574,\n",
       " 'heights': 8894,\n",
       " 'customers': 4116,\n",
       " 'drying': 8029,\n",
       " 'entertaining': 3016,\n",
       " 'hydrogen': 16143,\n",
       " 'wew': 12869,\n",
       " 'whiskey': 5666,\n",
       " 'month': 580,\n",
       " 'gettn': 9546,\n",
       " 'rafa': 4506,\n",
       " 'thing': 191,\n",
       " 'safe': 898,\n",
       " 'coverage': 3455,\n",
       " 'microwave': 5870,\n",
       " 'elliot': 8484,\n",
       " 'minds': 3637,\n",
       " 'pimple': 7612,\n",
       " 'impromptu': 11696,\n",
       " 'jessi': 14196,\n",
       " 'diesel': 11205,\n",
       " 'nhã': 17110,\n",
       " 'emma': 3400,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.word_index=worddict\n",
    "X_train= tokenizer.texts_to_sequences([\" \".join(x) for x in x_train])\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2019-05-14 12:25:37,568 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('phoneee', 0.5884519219398499),\n",
       " ('diploma', 0.5711613893508911),\n",
       " ('quothot', 0.5697406530380249),\n",
       " ('stamp', 0.5612384080886841),\n",
       " ('torres', 0.5602251291275024),\n",
       " ('headband', 0.5526103973388672),\n",
       " ('opensolaris', 0.5525676012039185),\n",
       " ('skull', 0.5496132969856262),\n",
       " ('growl', 0.5488866567611694),\n",
       " ('harddrive', 0.5478867292404175)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v.most_similar(\"tatt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=50)\n",
    "# X_train=X_train/28763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(input_dim=tweet_w2v.wv.syn0.shape[0], output_dim=tweet_w2v.wv.syn0.shape[1], weights=[tweet_w2v.wv.syn0], \n",
    "                            input_length=X_train.shape[1],trainable=False,mask_zero=True)\n",
    "# embedding_layer=tweet_w2v.wv.get_keras_embedding(train_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    5   79    7   13 9762] 0\n"
     ]
    }
   ],
   "source": [
    "# X_train=X_train[:100000]\n",
    "# y_train=y_train[:100000]\n",
    "print(X_train[0],\n",
    "y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-14 12:26:16,042 : WARNING : From /home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-14 12:26:20,002 : WARNING : From /home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 200)           3610800   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60)                62640     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               7808      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,681,377\n",
      "Trainable params: 70,577\n",
      "Non-trainable params: 3,610,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm_out = 60\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(LSTM(units=lstm_out,return_sequences=True,dropout=0.2,activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(LSTM(units=lstm_out,return_sequences=True,dropout=0.1))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(units=lstm_out))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt=keras.optimizers.Adam(decay=1e-6,lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= tokenizer.texts_to_sequences([\" \".join(x) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pad_sequences(X_test, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=keras.models.load_model('sent_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-14 12:26:31,554 : WARNING : From /home/nithin/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-14 12:26:33,692 : WARNING : Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800000 samples, validate on 200000 samples\n",
      "Epoch 1/5\n",
      "180736/800000 [=====>........................] - ETA: 44:27 - loss: 0.4578 - acc: 0.7834"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-dd443e9c8f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X_train, y_train, epochs=5, verbose=1, batch_size=batch_size,shuffle=True,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test=[x.words for x in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(X_test, y_test, verbose = 1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocAuc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "falsePositiveRate, truePositiveRate, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(falsePositiveRate, truePositiveRate, color='green',\n",
    "         lw=3, label='ROC curve (area = %0.2f)' % rocAuc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic of Sentiiment Analysis Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)\n",
    "#confusion metrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sent_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "good=\"i liked the movie\"\n",
    "bad=\"this movie was very nice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(tweet):\n",
    "    ntmp=tokenizer.texts_to_sequences([review])\n",
    "    tmp_padded=pad_sequences([ntmp][0],maxlen=50)\n",
    "    print(\"Sentiment %s\"%(model.predict_classes(np.array([tmp_padded][0]))[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment 1\n",
      "Sentiment 1\n"
     ]
    }
   ],
   "source": [
    "for review in [good,bad]:\n",
    "    sentiment(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.json\", \"w\") as write_file:\n",
    "    json.dump(worddict, write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
